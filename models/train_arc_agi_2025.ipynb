{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97ecff5",
   "metadata": {},
   "source": [
    "# ARC-AGI 2025: Training Notebook\n",
    "\n",
    "This notebook trains a baseline sequence-to-sequence Transformer on the generated ARC-AGI dataset (`artifacts/datasets/*.jsonl`).\n",
    "\n",
    "Sections:\n",
    "1. Setup\n",
    "2. Dependencies\n",
    "3. Device & Determinism\n",
    "4. Load Dataset\n",
    "5. Visualize Samples\n",
    "6. Tokenization & Augmentations\n",
    "7. Datasets & DataLoaders\n",
    "8. Transformer Model\n",
    "9. Loss/Optimizer/Scheduler\n",
    "10. Training Loop\n",
    "11. Validation Metrics\n",
    "12. Inference Solver\n",
    "13. Save Artifacts\n",
    "14. Unit Tests\n",
    "15. Hyperparameter Sweep (optional)\n",
    "16. Export to TorchScript/ONNX (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e703dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/aibe/Documents/Code/arc-agi\n",
      "Datasets dir: /home/aibe/Documents/Code/arc-agi/artifacts/datasets\n",
      "Run dir: /home/aibe/Documents/Code/arc-agi/models/run_20250809-185104\n"
     ]
    }
   ],
   "source": [
    "# Set Up Environment and Paths\n",
    "from __future__ import annotations\n",
    "import os, json, time, random\n",
    "from pathlib import Path\n",
    "\n",
    "# Robust project root detection for notebooks (no __file__)\n",
    "CWD = Path.cwd()\n",
    "CANDIDATES = [CWD, *CWD.parents]\n",
    "PROJECT_ROOT = None\n",
    "for p in CANDIDATES:\n",
    "    if (p / 'artifacts').exists() and (p / 'models').exists():\n",
    "        PROJECT_ROOT = p\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    # Fallback to two levels up from CWD\n",
    "    PROJECT_ROOT = CWD if (CWD / 'artifacts').exists() else CWD.parent\n",
    "\n",
    "DATASETS_DIR = PROJECT_ROOT / 'artifacts' / 'datasets'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_id = time.strftime('%Y%m%d-%H%M%S')\n",
    "RUN_DIR = MODELS_DIR / f'run_{run_id}'\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Project root:', PROJECT_ROOT)\n",
    "print('Datasets dir:', DATASETS_DIR)\n",
    "print('Run dir:', RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1146d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.5 (main, Jun 21 2025, 09:35:00) [GCC 15.1.1 20250425]\n",
      "Torch 2.8.0+cu128\n",
      "NumPy 2.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aibe/Documents/Code/arc-agi/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install and Import Dependencies\n",
    "import sys\n",
    "\n",
    "# Optional: install heavy deps if missing\n",
    "try:\n",
    "    import torch\n",
    "except Exception:\n",
    "    %pip install torch --quiet\n",
    "    import torch\n",
    "\n",
    "try:\n",
    "    import einops\n",
    "except Exception:\n",
    "    %pip install einops --quiet\n",
    "    import einops\n",
    "\n",
    "try:\n",
    "    import tqdm\n",
    "except Exception:\n",
    "    %pip install tqdm --quiet\n",
    "    import tqdm\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "except Exception:\n",
    "    %pip install matplotlib --quiet\n",
    "    import matplotlib\n",
    "\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Python', sys.version)\n",
    "print('Torch', torch.__version__)\n",
    "print('NumPy', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9674c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Detect Device and Configure Determinism\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "    except Exception:\n",
    "        pass\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "919a5421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 3232 | Val samples: 358\n"
     ]
    }
   ],
   "source": [
    "# Load ARC-AGI Dataset (from artifacts/datasets/*.jsonl)\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Sample:\n",
    "    split: str\n",
    "    task_id: str\n",
    "    subset: str\n",
    "    index: int\n",
    "    input: List[List[int]]\n",
    "    output: List[List[int]]\n",
    "    transform: dict\n",
    "\n",
    "\n",
    "def read_jsonl(path: Path):\n",
    "    with path.open('r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                yield json.loads(line)\n",
    "\n",
    "\n",
    "def load_split(name: str):\n",
    "    path = DATASETS_DIR / f'{name}.jsonl'\n",
    "    if not path.exists():\n",
    "        print(f'Warning: dataset not found: {path}')\n",
    "        return []\n",
    "    data = []\n",
    "    for rec in read_jsonl(path):\n",
    "        if 'input' in rec and 'output' in rec:\n",
    "            data.append(Sample(\n",
    "                split=rec['split'], task_id=rec['task_id'], subset=rec['subset'], index=rec['index'],\n",
    "                input=rec['input'], output=rec['output'], transform=rec.get('transform', {})\n",
    "            ))\n",
    "    return data\n",
    "\n",
    "train_samples = load_split('training')\n",
    "val_samples = load_split('evaluation')  # use evaluation as validation if present\n",
    "if not val_samples and len(train_samples) > 10:\n",
    "    n = int(0.9 * len(train_samples))\n",
    "    val_samples = train_samples[n:]\n",
    "    train_samples = train_samples[:n]\n",
    "\n",
    "print(f'Train samples: {len(train_samples)} | Val samples: {len(val_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Sample Tasks\n",
    "from itertools import islice\n",
    "\n",
    "def show_grid(ax, grid, title=\"\"):\n",
    "    arr = np.array(grid, dtype=int)\n",
    "    cmap = plt.get_cmap('tab10', 10)\n",
    "    ax.imshow(arr, cmap=cmap, vmin=0, vmax=9)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(10,5))\n",
    "axes = axes.ravel()\n",
    "for i, s in enumerate(islice(train_samples, 4)):\n",
    "    show_grid(axes[2*i], s.input, f\"Train Input {i}\")\n",
    "    show_grid(axes[2*i+1], s.output, f\"Train Output {i}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8701ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 14\n"
     ]
    }
   ],
   "source": [
    "# Encode Grids to Tokens and Augmentations\n",
    "PAD, BOS, EOS, SEP = 10, 11, 12, 13\n",
    "VOCAB_SIZE = 14  # 0-9 colors + 4 specials\n",
    "\n",
    "def normalize_grid(grid: List[List[int]] | List[int] | int) -> np.ndarray:\n",
    "    arr = np.array(grid, dtype=int)\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.reshape(1, 1)\n",
    "    elif arr.ndim == 1:\n",
    "        arr = arr.reshape(1, -1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def encode_grid(grid: List[List[int]] | List[int] | int) -> List[int]:\n",
    "    arr = normalize_grid(grid)\n",
    "    return arr.reshape(-1).tolist()\n",
    "\n",
    "def decode_grid(tokens: List[int], h: int, w: int) -> List[List[int]]:\n",
    "    seq = tokens[: h*w]\n",
    "    return [seq[i*w:(i+1)*w] for i in range(h)]\n",
    "\n",
    "AUG_ROT = [0, 1, 2, 3]\n",
    "AUG_FLIP = [False, True]\n",
    "\n",
    "def apply_aug(grid):\n",
    "    arr = normalize_grid(grid)\n",
    "    # Only apply geometric augs when >0 dims\n",
    "    if arr.shape[0] > 0 and arr.shape[1] > 0:\n",
    "        k = random.choice(AUG_ROT)\n",
    "        if k:\n",
    "            arr = np.rot90(arr, k)\n",
    "        if random.choice(AUG_FLIP):\n",
    "            arr = np.fliplr(arr)\n",
    "        # random color permutation over observed colors\n",
    "        vals = sorted(set(arr.ravel().tolist()))\n",
    "        if len(vals) > 1:\n",
    "            perm = vals[:]\n",
    "            random.shuffle(perm)\n",
    "            mp = {a:b for a,b in zip(vals, perm)}\n",
    "            vfunc = np.vectorize(lambda x: mp.get(int(x), int(x)))\n",
    "            arr = vfunc(arr)\n",
    "    return arr.astype(int).tolist()\n",
    "\n",
    "print('Vocab size:', VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f43ff0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 23)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch Dataset and DataLoaders\n",
    "MAX_H, MAX_W = 30, 30  # ARC grids are typically <= 30\n",
    "\n",
    "def to_2d(grid):\n",
    "    if grid is None:\n",
    "        return []\n",
    "    if isinstance(grid, (int, np.integer)):\n",
    "        return [[int(grid)]]\n",
    "    if isinstance(grid, list):\n",
    "        if not grid:\n",
    "            return []\n",
    "        if isinstance(grid[0], list):\n",
    "            return grid\n",
    "        else:\n",
    "            return [grid]\n",
    "    arr = np.array(grid)\n",
    "    if arr.ndim == 0:\n",
    "        return [[int(arr)]]\n",
    "    if arr.ndim == 1:\n",
    "        return [arr.astype(int).tolist()]\n",
    "    return arr.astype(int).tolist()\n",
    "\n",
    "class ArcSeqDataset(Dataset):\n",
    "    def __init__(self, samples, augment=False):\n",
    "        self.samples = samples\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        inp = to_2d(s.input)\n",
    "        out = to_2d(s.output)\n",
    "        if self.augment:\n",
    "            inp = apply_aug(inp)\n",
    "            out = apply_aug(out)\n",
    "        h_in, w_in = len(inp), len(inp[0]) if inp and len(inp) > 0 else 0\n",
    "        h_out, w_out = len(out), len(out[0]) if out and len(out) > 0 else 0\n",
    "        enc = encode_grid(inp)\n",
    "        dec_tgt = encode_grid(out)\n",
    "        dec_in = [BOS] + dec_tgt[:-1] if len(dec_tgt) > 0 else [BOS]\n",
    "        return {\n",
    "            'enc': torch.tensor(enc, dtype=torch.long),\n",
    "            'dec_in': torch.tensor(dec_in, dtype=torch.long),\n",
    "            'tgt': torch.tensor(dec_tgt, dtype=torch.long),\n",
    "            'h_in': h_in, 'w_in': w_in, 'h_out': h_out, 'w_out': w_out\n",
    "        }\n",
    "\n",
    "\n",
    "def make_row_col_indices(h, w):\n",
    "    rows = np.repeat(np.arange(h), w) if (h > 0 and w > 0) else np.array([], dtype=int)\n",
    "    cols = np.tile(np.arange(w), h) if (h > 0 and w > 0) else np.array([], dtype=int)\n",
    "    return rows, cols\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    B = len(batch)\n",
    "    enc_lens = [len(b['enc']) for b in batch]\n",
    "    dec_lens = [len(b['dec_in']) for b in batch]\n",
    "    max_enc = max(enc_lens) if enc_lens else 0\n",
    "    max_dec = max(dec_lens) if dec_lens else 0\n",
    "\n",
    "    enc = torch.full((B, max_enc), PAD, dtype=torch.long)\n",
    "    dec_in = torch.full((B, max_dec), PAD, dtype=torch.long)\n",
    "    tgt = torch.full((B, max_dec), PAD, dtype=torch.long)\n",
    "\n",
    "    enc_pad_mask = torch.ones((B, max_enc), dtype=torch.bool)  # True for pad\n",
    "    dec_pad_mask = torch.ones((B, max_dec), dtype=torch.bool)\n",
    "\n",
    "    row_idx = torch.zeros((B, max_enc), dtype=torch.long)\n",
    "    col_idx = torch.zeros((B, max_enc), dtype=torch.long)\n",
    "\n",
    "    meta = []\n",
    "    for i, b in enumerate(batch):\n",
    "        L_e = len(b['enc']); L_d = len(b['dec_in'])\n",
    "        enc[i, :L_e] = b['enc']\n",
    "        dec_in[i, :L_d] = b['dec_in']\n",
    "        tgt[i, :len(b['tgt'])] = b['tgt']\n",
    "        enc_pad_mask[i, :L_e] = False\n",
    "        dec_pad_mask[i, :L_d] = False\n",
    "        r, c = make_row_col_indices(b['h_in'], b['w_in'])\n",
    "        if L_e > 0 and len(r) == L_e:\n",
    "            row_idx[i, :L_e] = torch.tensor(r, dtype=torch.long)\n",
    "            col_idx[i, :L_e] = torch.tensor(c, dtype=torch.long)\n",
    "        meta.append((b['h_in'], b['w_in'], b['h_out'], b['w_out']))\n",
    "\n",
    "    return {\n",
    "        'enc': enc, 'dec_in': dec_in, 'tgt': tgt,\n",
    "        'enc_pad_mask': enc_pad_mask, 'dec_pad_mask': dec_pad_mask,\n",
    "        'row_idx': row_idx, 'col_idx': col_idx, 'meta': meta\n",
    "    }\n",
    "\n",
    "train_ds = ArcSeqDataset(train_samples, augment=True)\n",
    "val_ds = ArcSeqDataset(val_samples, augment=False)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEM = (device.type == 'cuda')\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEM, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=PIN_MEM, collate_fn=collate_batch)\n",
    "\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50e8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transformer Model for ARC\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=4096):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0), persistent=False)\n",
    "    def forward(self, x):\n",
    "        L = x.size(1)\n",
    "        return x + self.pe[:, :L]\n",
    "\n",
    "class ArcTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, d_model=128, nhead=4, num_layers=3, dim_ff=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.row_emb = nn.Embedding(64, d_model)\n",
    "        self.col_emb = nn.Embedding(64, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_ff, dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_ff, dropout, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def encode(self, enc_tokens, row_idx, col_idx, src_key_padding_mask=None):\n",
    "        x = self.tok_emb(enc_tokens) + self.row_emb(row_idx) + self.col_emb(col_idx)\n",
    "        x = self.pos_enc(x)\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        return x\n",
    "\n",
    "    def decode(self, dec_tokens, memory, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        y = self.tok_emb(dec_tokens)\n",
    "        y = self.pos_enc(y)\n",
    "        L = y.size(1)\n",
    "        causal_mask = torch.triu(torch.ones(L, L, device=y.device, dtype=torch.bool), diagonal=1)\n",
    "        y = self.decoder(y, memory, tgt_mask=causal_mask,\n",
    "                         tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                         memory_key_padding_mask=memory_key_padding_mask)\n",
    "        return self.proj(y)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        memory = self.encode(batch['enc'], batch['row_idx'], batch['col_idx'], src_key_padding_mask=batch['enc_pad_mask'])\n",
    "        logits = self.decode(batch['dec_in'], memory,\n",
    "                             tgt_key_padding_mask=batch['dec_pad_mask'],\n",
    "                             memory_key_padding_mask=batch['enc_pad_mask'])\n",
    "        return logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, enc, row_idx, col_idx, enc_pad_mask, max_len=256):\n",
    "        self.eval()\n",
    "        memory = self.encode(enc, row_idx, col_idx, src_key_padding_mask=enc_pad_mask)\n",
    "        B = enc.size(0)\n",
    "        ys = torch.full((B, 1), BOS, dtype=torch.long, device=enc.device)\n",
    "        for _ in range(max_len):\n",
    "            logits = self.decode(ys, memory,\n",
    "                                 tgt_key_padding_mask=torch.zeros_like(ys, dtype=torch.bool),\n",
    "                                 memory_key_padding_mask=enc_pad_mask)\n",
    "            next_tok = logits[:, -1].argmax(-1, keepdim=True)\n",
    "            ys = torch.cat([ys, next_tok], dim=1)\n",
    "            if (next_tok == EOS).all():\n",
    "                break\n",
    "        return ys[:, 1:]  # drop BOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dfee4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.013774 M params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_526498/3418346925.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n"
     ]
    }
   ],
   "source": [
    "# Configure Loss, Optimizer, and Scheduler\n",
    "model = ArcTransformer().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9ce7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]: 100%|██████████| 202/202 [17:00<00:00,  5.05s/it, loss=0.857]\n",
      "Epoch 1 [train]: 100%|██████████| 202/202 [17:00<00:00,  5.05s/it, loss=0.857]\n",
      "Epoch 1 [val]: 100%|██████████| 23/23 [00:18<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 val_loss=0.8127\n",
      "Saved new best to /home/aibe/Documents/Code/arc-agi/models/run_20250809-185104/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Loop with Mixed Precision and Checkpointing\n",
    "EPOCHS = 1\n",
    "ACCUM_STEPS = 1\n",
    "BEST_VAL = float('inf')\n",
    "\n",
    "best_path = RUN_DIR / 'best.pt'\n",
    "last_path = RUN_DIR / 'last.pt'\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch} [train]')\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for step, batch in enumerate(pbar, 1):\n",
    "        for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "            batch[k] = batch[k].to(device)\n",
    "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
    "            logits = model(batch)\n",
    "            B, L, V = logits.shape\n",
    "            loss = criterion(logits.view(B*L, V), batch['tgt'].view(B*L)) / ACCUM_STEPS\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if step % ACCUM_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        total_loss += loss.item() * ACCUM_STEPS\n",
    "        pbar.set_postfix(loss=total_loss/step)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f'Epoch {epoch} [val]'):\n",
    "            for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "                batch[k] = batch[k].to(device)\n",
    "            logits = model(batch)\n",
    "            B, L, V = logits.shape\n",
    "            loss = criterion(logits.view(B*L, V), batch['tgt'].view(B*L))\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= max(1, len(val_loader))\n",
    "    print(f'Epoch {epoch} val_loss={val_loss:.4f}')\n",
    "\n",
    "    # Checkpoint\n",
    "    torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(),\n",
    "                'epoch': epoch}, last_path)\n",
    "    if val_loss < BEST_VAL:\n",
    "        BEST_VAL = val_loss\n",
    "        torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': epoch}, best_path)\n",
    "        print('Saved new best to', best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f968054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate and Compute ARC Metrics\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    exact = 0\n",
    "    total = 0\n",
    "    cell_correct = 0\n",
    "    cell_total = 0\n",
    "    for batch in tqdm(loader, desc='Eval'): \n",
    "        for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "            batch[k] = batch[k].to(device)\n",
    "        logits = model(batch)\n",
    "        preds = logits.argmax(-1)\n",
    "        mask = batch['tgt'] != PAD\n",
    "        equal = (preds == batch['tgt']) & mask\n",
    "        cell_correct += equal.sum().item()\n",
    "        cell_total += mask.sum().item()\n",
    "        # exact match per sequence\n",
    "        seq_equal = (equal.sum(dim=1) == mask.sum(dim=1))\n",
    "        exact += seq_equal.sum().item()\n",
    "        total += preds.size(0)\n",
    "    return {\n",
    "        'exact_match': exact / max(1, total),\n",
    "        'cell_accuracy': cell_correct / max(1, cell_total)\n",
    "    }\n",
    "\n",
    "metrics = evaluate(model, val_loader)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6189452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference: Solve Unseen Tasks\n",
    "@torch.no_grad()\n",
    "def solve_batch(model, batch, max_len=256):\n",
    "    for k in ['enc','enc_pad_mask','row_idx','col_idx']:\n",
    "        batch[k] = batch[k].to(device)\n",
    "    gen = model.generate(batch['enc'], batch['row_idx'], batch['col_idx'], batch['enc_pad_mask'], max_len=max_len)\n",
    "    preds = gen.cpu().numpy().tolist()\n",
    "    outputs = []\n",
    "    for i, (h_in, w_in, h_out, w_out) in enumerate(batch['meta']):\n",
    "        outputs.append(decode_grid(preds[i], h_out, w_out))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Artifacts to models/\n",
    "config = {\n",
    "    'model': 'ArcTransformer', 'vocab_size': VOCAB_SIZE,\n",
    "    'd_model': 256, 'nhead': 8, 'num_layers': 4, 'dim_ff': 512,\n",
    "    'batch_size': BATCH_SIZE, 'epochs': EPOCHS, 'seed': SEED,\n",
    "}\n",
    "\n",
    "metrics = evaluate(model, val_loader)\n",
    "with (RUN_DIR / 'metrics.json').open('w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "torch.save({'model': model.state_dict(), 'config': config}, RUN_DIR / 'model.pt')\n",
    "with (RUN_DIR / 'config.json').open('w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print('Saved to', RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c11329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight Unit Tests\n",
    "# 1) Encode/Decode roundtrip\n",
    "_grid = [[1,2,3],[4,5,6]]\n",
    "assert decode_grid(encode_grid(_grid), 2, 3) == _grid\n",
    "print('Encode/Decode test passed')\n",
    "\n",
    "# 2) Batch forward pass sanity\n",
    "batch = next(iter(train_loader))\n",
    "for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "    batch[k] = batch[k].to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(batch)\n",
    "assert logits.shape[:2] == batch['tgt'].shape\n",
    "print('Forward pass shape test passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32aeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Hyperparameter Sweep Hook\n",
    "from itertools import product\n",
    "\n",
    "def sweep(grid):\n",
    "    results = []\n",
    "    for (lr, layers, heads, dropout) in product(grid['lr'], grid['layers'], grid['heads'], grid['dropout']):\n",
    "        m = ArcTransformer(num_layers=layers, nhead=heads).to(device)\n",
    "        opt = torch.optim.AdamW(m.parameters(), lr=lr)\n",
    "        # One minibatch quick score\n",
    "        batch = next(iter(train_loader))\n",
    "        for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "            batch[k] = batch[k].to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = m(batch)\n",
    "            B, L, V = logits.shape\n",
    "            loss = criterion(logits.view(B*L, V), batch['tgt'].view(B*L)).item()\n",
    "        results.append({'lr': lr, 'layers': layers, 'heads': heads, 'dropout': dropout, 'loss': loss})\n",
    "    return sorted(results, key=lambda x: x['loss'])\n",
    "\n",
    "# Example sweep grid (commented)\n",
    "# grid = {'lr':[1e-4,3e-4], 'layers':[3,4], 'heads':[4,8], 'dropout':[0.0,0.1]}\n",
    "# sweep_results = sweep(grid)\n",
    "# sweep_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e2d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Export to TorchScript/ONNX\n",
    "try:\n",
    "    example = next(iter(val_loader))\n",
    "    for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "        example[k] = example[k].to(device)\n",
    "    ts_path = RUN_DIR / 'model_ts.pt'\n",
    "    scripted = torch.jit.trace(model, (example))  # may fail for dict input\n",
    "    scripted.save(str(ts_path))\n",
    "    print('Saved TorchScript to', ts_path)\n",
    "except Exception as e:\n",
    "    print('TorchScript export skipped:', e)\n",
    "\n",
    "try:\n",
    "    import onnx\n",
    "    onnx_path = RUN_DIR / 'model.onnx'\n",
    "    # ONNX export with dynamic axes is non-trivial for dict inputs; skipping here\n",
    "    print('ONNX export not implemented in this baseline')\n",
    "except Exception as e:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
