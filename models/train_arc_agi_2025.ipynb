{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97ecff5",
   "metadata": {},
   "source": [
    "# ARC-AGI 2025: Training Notebook\n",
    "\n",
    "This notebook trains a baseline sequence-to-sequence Transformer on the generated ARC-AGI dataset (`artifacts/datasets/*.jsonl`).\n",
    "\n",
    "Sections:\n",
    "1. Setup\n",
    "2. Dependencies\n",
    "3. Device & Determinism\n",
    "4. Load Dataset\n",
    "5. Visualize Samples\n",
    "6. Tokenization & Augmentations\n",
    "7. Datasets & DataLoaders\n",
    "8. Transformer Model\n",
    "9. Loss/Optimizer/Scheduler\n",
    "10. Training Loop\n",
    "11. Validation Metrics\n",
    "12. Inference Solver\n",
    "13. Save Artifacts\n",
    "14. Unit Tests\n",
    "15. Hyperparameter Sweep (optional)\n",
    "16. Export to TorchScript/ONNX (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14e703dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\n",
      "Datasets dir: c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\artifacts\\datasets\n",
      "Run dir: c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os, json, time, random\n",
    "from pathlib import Path\n",
    "CWD = Path.cwd()\n",
    "CANDIDATES = [CWD, *CWD.parents]\n",
    "PROJECT_ROOT = None\n",
    "for p in CANDIDATES:\n",
    "    if (p / 'artifacts').exists() and (p / 'models').exists():\n",
    "        PROJECT_ROOT = p\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    PROJECT_ROOT = CWD if (CWD / 'artifacts').exists() else CWD.parent\n",
    "DATASETS_DIR = PROJECT_ROOT / 'artifacts' / 'datasets'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "run_id = time.strftime('%Y%m%d-%H%M%S')\n",
    "RUN_DIR = MODELS_DIR / f'run_{run_id}'\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Project root:', PROJECT_ROOT)\n",
    "print('Datasets dir:', DATASETS_DIR)\n",
    "print('Run dir:', RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1146d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Torch 2.8.0+cpu\n",
      "NumPy 2.3.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "try:\n",
    "    import torch\n",
    "except Exception:\n",
    "    %pip install torch --quiet\n",
    "    import torch\n",
    "try:\n",
    "    import einops\n",
    "except Exception:\n",
    "    %pip install einops --quiet\n",
    "    import einops\n",
    "try:\n",
    "    import tqdm\n",
    "except Exception:\n",
    "    %pip install tqdm --quiet\n",
    "    import tqdm\n",
    "try:\n",
    "    import matplotlib\n",
    "except Exception:\n",
    "    %pip install matplotlib --quiet\n",
    "    import matplotlib\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "print('Python', sys.version)\n",
    "print('Torch', torch.__version__)\n",
    "print('NumPy', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9674c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "    except Exception:\n",
    "        pass\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "919a5421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 3232 | Val samples: 358\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Sample:\n",
    "    split: str\n",
    "    task_id: str\n",
    "    subset: str\n",
    "    index: int\n",
    "    input: List[List[int]]\n",
    "    output: List[List[int]]\n",
    "    transform: dict\n",
    "\n",
    "def read_jsonl(path: Path):\n",
    "    with path.open('r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                yield json.loads(line)\n",
    "\n",
    "def load_split(name: str):\n",
    "    path = DATASETS_DIR / f'{name}.jsonl'\n",
    "    if not path.exists():\n",
    "        print(f'Warning: dataset not found: {path}')\n",
    "        return []\n",
    "    data = []\n",
    "    for rec in read_jsonl(path):\n",
    "        if 'input' in rec and 'output' in rec:\n",
    "            data.append(Sample(\n",
    "                split=rec['split'], task_id=rec['task_id'], subset=rec['subset'], index=rec['index'],\n",
    "                input=rec['input'], output=rec['output'], transform=rec.get('transform', {})\n",
    "            ))\n",
    "    return data\n",
    "train_samples = load_split('training')\n",
    "val_samples = load_split('evaluation')\n",
    "if not val_samples and len(train_samples) > 10:\n",
    "    n = int(0.9 * len(train_samples))\n",
    "    val_samples = train_samples[n:]\n",
    "    train_samples = train_samples[:n]\n",
    "print(f'Train samples: {len(train_samples)} | Val samples: {len(val_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c223f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small experiment: train=180 val=20 (orig train=3232 val=358)\n"
     ]
    }
   ],
   "source": [
    "# === Small Experiment Subset Setup ===\n",
    "# Reduce dataset size for a fast baseline experiment run.\n",
    "MAX_TRAIN = 200           # cap number of training examples considered (set None for full)\n",
    "VAL_RATIO = 0.1           # portion of (post-cap) training examples to use as validation if evaluation split empty\n",
    "FORCE_RESPLIT = True      # force re-splitting even if evaluation examples exist (set False to keep evaluation split)\n",
    "\n",
    "original_train_len = len(train_samples)\n",
    "original_val_len = len(val_samples)\n",
    "\n",
    "# Cap train set\n",
    "if MAX_TRAIN is not None and len(train_samples) > MAX_TRAIN:\n",
    "    train_samples = train_samples[:MAX_TRAIN]\n",
    "\n",
    "# Re-split if evaluation empty or forced\n",
    "if FORCE_RESPLIT or (not val_samples):\n",
    "    cut = int(len(train_samples) * (1 - VAL_RATIO))\n",
    "    if cut <= 0: cut = max(1, len(train_samples) - 1)\n",
    "    val_samples = train_samples[cut:]\n",
    "    train_samples = train_samples[:cut]\n",
    "\n",
    "print(f\"Small experiment: train={len(train_samples)} val={len(val_samples)} (orig train={original_train_len} val={original_val_len})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "998c4e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "def show_grid(ax, grid, title=\"\"):\n",
    "    arr = np.array(grid, dtype=int)\n",
    "    cmap = plt.get_cmap('tab10', 10)\n",
    "    ax.imshow(arr, cmap=cmap, vmin=0, vmax=9)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "fig, axes = plt.subplots(2, 4, figsize=(10,5))\n",
    "axes = axes.ravel()\n",
    "for i, s in enumerate(islice(train_samples, 4)):\n",
    "    show_grid(axes[2*i], s.input, f\"Train Input {i}\")\n",
    "    show_grid(axes[2*i+1], s.output, f\"Train Output {i}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a8701ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 14\n"
     ]
    }
   ],
   "source": [
    "PAD, BOS, EOS, SEP = 10, 11, 12, 13\n",
    "VOCAB_SIZE = 14\n",
    "\n",
    "def normalize_grid(grid: List[List[int]] | List[int] | int) -> np.ndarray:\n",
    "    arr = np.array(grid, dtype=int)\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.reshape(1, 1)\n",
    "    elif arr.ndim == 1:\n",
    "        arr = arr.reshape(1, -1)\n",
    "    return arr\n",
    "\n",
    "def encode_grid(grid: List[List[int]] | List[int] | int) -> List[int]:\n",
    "    arr = normalize_grid(grid)\n",
    "    return arr.reshape(-1).tolist()\n",
    "\n",
    "def decode_grid(tokens: List[int], h: int, w: int) -> List[List[int]]:\n",
    "    seq = tokens[: h*w]\n",
    "    return [seq[i*w:(i+1)*w] for i in range(h)]\n",
    "AUG_ROT = [0, 1, 2, 3]\n",
    "AUG_FLIP = [False, True]\n",
    "\n",
    "# --- Paired augmentation (applied consistently to input and output) ---\n",
    "\n",
    "def _sample_aug_params(arr_in: np.ndarray, arr_out: np.ndarray):\n",
    "    rot = random.choice(AUG_ROT)\n",
    "    flip = random.choice(AUG_FLIP)\n",
    "    vals = sorted(set(arr_in.ravel().tolist()) | set(arr_out.ravel().tolist()))\n",
    "    cmap = {}\n",
    "    if len(vals) > 1:\n",
    "        perm = vals[:]\n",
    "        random.shuffle(perm)\n",
    "        cmap = {a: b for a, b in zip(vals, perm)}\n",
    "    return {\"rot\": rot, \"flip\": flip, \"cmap\": cmap}\n",
    "\n",
    "def _apply_aug_with_params(arr: np.ndarray, params):\n",
    "    if params[\"rot\"]:\n",
    "        arr = np.rot90(arr, params[\"rot\"])\n",
    "    if params[\"flip\"]:\n",
    "        arr = np.fliplr(arr)\n",
    "    if params[\"cmap\"]:\n",
    "        vfunc = np.vectorize(lambda x: params[\"cmap\"].get(int(x), int(x)))\n",
    "        arr = vfunc(arr)\n",
    "    return arr\n",
    "\n",
    "def apply_shared_aug(inp_grid, out_grid):\n",
    "    arr_in = normalize_grid(inp_grid)\n",
    "    arr_out = normalize_grid(out_grid)\n",
    "    if arr_in.size == 0 or arr_out.size == 0:\n",
    "        return inp_grid, out_grid\n",
    "    params = _sample_aug_params(arr_in, arr_out)\n",
    "    aug_in = _apply_aug_with_params(arr_in, params)\n",
    "    aug_out = _apply_aug_with_params(arr_out, params)\n",
    "    return aug_in.astype(int).tolist(), aug_out.astype(int).tolist()\n",
    "\n",
    "print('Vocab size:', VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f43ff0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_H, MAX_W = 30, 30\n",
    "\n",
    "def to_2d(grid):\n",
    "    if grid is None:\n",
    "        return []\n",
    "    if isinstance(grid, (int, np.integer)):\n",
    "        return [[int(grid)]]\n",
    "    if isinstance(grid, list):\n",
    "        if not grid:\n",
    "            return []\n",
    "        if isinstance(grid[0], list):\n",
    "            return grid\n",
    "        else:\n",
    "            return [grid]\n",
    "    arr = np.array(grid)\n",
    "    if arr.ndim == 0:\n",
    "        return [[int(arr)]]\n",
    "    if arr.ndim == 1:\n",
    "        return [arr.astype(int).tolist()]\n",
    "    return arr.astype(int).tolist()\n",
    "class ArcSeqDataset(Dataset):\n",
    "    def __init__(self, samples, augment=False):\n",
    "        self.samples = samples\n",
    "        self.augment = augment\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        inp = to_2d(s.input)\n",
    "        out = to_2d(s.output)\n",
    "        if self.augment:\n",
    "            inp, out = apply_shared_aug(inp, out)\n",
    "        h_in, w_in = len(inp), len(inp[0]) if inp and len(inp) > 0 else 0\n",
    "        h_out, w_out = len(out), len(out[0]) if out and len(out) > 0 else 0\n",
    "        enc = encode_grid(inp)\n",
    "        dec_tgt_core = encode_grid(out)\n",
    "        dec_tgt = dec_tgt_core + [EOS]\n",
    "        dec_in = [BOS] + dec_tgt[:-1]\n",
    "        return {\n",
    "            'enc': torch.tensor(enc, dtype=torch.long),\n",
    "            'dec_in': torch.tensor(dec_in, dtype=torch.long),\n",
    "            'tgt': torch.tensor(dec_tgt, dtype=torch.long),\n",
    "            'h_in': h_in, 'w_in': w_in, 'h_out': h_out, 'w_out': w_out\n",
    "        }\n",
    "\n",
    "def make_row_col_indices(h, w):\n",
    "    rows = np.repeat(np.arange(h), w) if (h > 0 and w > 0) else np.array([], dtype=int)\n",
    "    cols = np.tile(np.arange(w), h) if (h > 0 and w > 0) else np.array([], dtype=int)\n",
    "    return rows, cols\n",
    "\n",
    "def collate_batch(batch):\n",
    "    B = len(batch)\n",
    "    enc_lens = [len(b['enc']) for b in batch]\n",
    "    dec_lens = [len(b['dec_in']) for b in batch]\n",
    "    max_enc = max(enc_lens) if enc_lens else 0\n",
    "    max_dec = max(dec_lens) if dec_lens else 0\n",
    "    enc = torch.full((B, max_enc), PAD, dtype=torch.long)\n",
    "    dec_in = torch.full((B, max_dec), PAD, dtype=torch.long)\n",
    "    tgt = torch.full((B, max_dec), PAD, dtype=torch.long)\n",
    "    enc_pad_mask = torch.ones((B, max_enc), dtype=torch.bool)\n",
    "    dec_pad_mask = torch.ones((B, max_dec), dtype=torch.bool)\n",
    "    row_idx = torch.zeros((B, max_enc), dtype=torch.long)\n",
    "    col_idx = torch.zeros((B, max_enc), dtype=torch.long)\n",
    "    meta = []\n",
    "    for i, b in enumerate(batch):\n",
    "        L_e = len(b['enc']); L_d = len(b['dec_in'])\n",
    "        enc[i, :L_e] = b['enc']\n",
    "        dec_in[i, :L_d] = b['dec_in']\n",
    "        tgt[i, :len(b['tgt'])] = b['tgt']\n",
    "        enc_pad_mask[i, :L_e] = False\n",
    "        dec_pad_mask[i, :L_d] = False\n",
    "        r, c = make_row_col_indices(b['h_in'], b['w_in'])\n",
    "        if L_e > 0 and len(r) == L_e:\n",
    "            row_idx[i, :L_e] = torch.tensor(r, dtype=torch.long)\n",
    "            col_idx[i, :L_e] = torch.tensor(c, dtype=torch.long)\n",
    "        meta.append((b['h_in'], b['w_in'], b['h_out'], b['w_out']))\n",
    "    return {\n",
    "        'enc': enc, 'dec_in': dec_in, 'tgt': tgt,\n",
    "        'enc_pad_mask': enc_pad_mask, 'dec_pad_mask': dec_pad_mask,\n",
    "        'row_idx': row_idx, 'col_idx': col_idx, 'meta': meta\n",
    "    }\n",
    "train_ds = ArcSeqDataset(train_samples, augment=True)\n",
    "val_ds = ArcSeqDataset(val_samples, augment=False)\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEM = (device.type == 'cuda')\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEM, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=PIN_MEM, collate_fn=collate_batch)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a50e8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=4096):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0), persistent=False)\n",
    "    def forward(self, x):\n",
    "        L = x.size(1)\n",
    "        return x + self.pe[:, :L]\n",
    "class ArcTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, d_model=128, nhead=4, num_layers=3, dim_ff=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.row_emb = nn.Embedding(64, d_model)\n",
    "        self.col_emb = nn.Embedding(64, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_ff, dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_ff, dropout, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "    def encode(self, enc_tokens, row_idx, col_idx, src_key_padding_mask=None):\n",
    "        x = self.tok_emb(enc_tokens) + self.row_emb(row_idx) + self.col_emb(col_idx)\n",
    "        x = self.pos_enc(x)\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        return x\n",
    "    def decode(self, dec_tokens, memory, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        y = self.tok_emb(dec_tokens)\n",
    "        y = self.pos_enc(y)\n",
    "        L = y.size(1)\n",
    "        causal_mask = torch.triu(torch.ones(L, L, device=y.device, dtype=torch.bool), diagonal=1)\n",
    "        y = self.decoder(y, memory, tgt_mask=causal_mask,\n",
    "                         tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                         memory_key_padding_mask=memory_key_padding_mask)\n",
    "        return self.proj(y)\n",
    "    def forward(self, batch):\n",
    "        memory = self.encode(batch['enc'], batch['row_idx'], batch['col_idx'], src_key_padding_mask=batch['enc_pad_mask'])\n",
    "        logits = self.decode(batch['dec_in'], memory,\n",
    "                             tgt_key_padding_mask=batch['dec_pad_mask'],\n",
    "                             memory_key_padding_mask=batch['enc_pad_mask'])\n",
    "        return logits\n",
    "    @torch.no_grad()\n",
    "    def generate(self, enc, row_idx, col_idx, enc_pad_mask, max_len=256):\n",
    "        self.eval()\n",
    "        memory = self.encode(enc, row_idx, col_idx, src_key_padding_mask=enc_pad_mask)\n",
    "        B = enc.size(0)\n",
    "        ys = torch.full((B, 1), BOS, dtype=torch.long, device=enc.device)\n",
    "        for _ in range(max_len):\n",
    "            logits = self.decode(ys, memory,\n",
    "                                 tgt_key_padding_mask=torch.zeros_like(ys, dtype=torch.bool),\n",
    "                                 memory_key_padding_mask=enc_pad_mask)\n",
    "            next_tok = logits[:, -1].argmax(-1, keepdim=True)\n",
    "            ys = torch.cat([ys, next_tok], dim=1)\n",
    "            if (next_tok == EOS).all():\n",
    "                break\n",
    "        return ys[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dfee4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.389006 M params (small experiment model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aibel\\AppData\\Local\\Temp\\ipykernel_14172\\1090104874.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n"
     ]
    }
   ],
   "source": [
    "model = ArcTransformer(d_model=96, nhead=4, num_layers=2, dim_ff=192).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M params (small experiment model)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b9ce7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n",
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n",
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss=2.0866 val_loss=1.8329\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [val]: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n",
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss=2.0866 val_loss=1.8329\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [val]: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train_loss=1.4689 val_loss=1.3782\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [train]: 100%|██████████| 12/12 [01:36<00:00,  8.03s/it, loss=1.22]\n",
      "Epoch 3 [train]: 100%|██████████| 12/12 [01:36<00:00,  8.03s/it, loss=1.22]\n",
      "Epoch 3 [val]: 100%|██████████| 2/2 [00:00<00:00,  3.05it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n",
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss=2.0866 val_loss=1.8329\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [val]: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train_loss=1.4689 val_loss=1.3782\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [train]: 100%|██████████| 12/12 [01:36<00:00,  8.03s/it, loss=1.22]\n",
      "Epoch 3 [train]: 100%|██████████| 12/12 [01:36<00:00,  8.03s/it, loss=1.22]\n",
      "Epoch 3 [val]: 100%|██████████| 2/2 [00:00<00:00,  3.05it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train_loss=1.2226 val_loss=1.2749\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [train]: 100%|██████████| 12/12 [01:33<00:00,  7.80s/it, loss=1.16]\n",
      "Epoch 4 [train]: 100%|██████████| 12/12 [01:33<00:00,  7.80s/it, loss=1.16]\n",
      "Epoch 4 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n",
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss=2.0866 val_loss=1.8329\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [val]: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train_loss=1.4689 val_loss=1.3782\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [train]: 100%|██████████| 12/12 [01:36<00:00,  8.03s/it, loss=1.22]\n",
      "Epoch 3 [train]: 100%|██████████| 12/12 [01:36<00:00,  8.03s/it, loss=1.22]\n",
      "Epoch 3 [val]: 100%|██████████| 2/2 [00:00<00:00,  3.05it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train_loss=1.2226 val_loss=1.2749\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [train]: 100%|██████████| 12/12 [01:33<00:00,  7.80s/it, loss=1.16]\n",
      "Epoch 4 [train]: 100%|██████████| 12/12 [01:33<00:00,  7.80s/it, loss=1.16]\n",
      "Epoch 4 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train_loss=1.1626 val_loss=1.1869\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [train]: 100%|██████████| 12/12 [01:35<00:00,  7.95s/it, loss=1.04]\n",
      "Epoch 5 [train]: 100%|██████████| 12/12 [01:35<00:00,  7.95s/it, loss=1.04]\n",
      "Epoch 5 [val]: 100%|██████████| 2/2 [00:00<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n",
      "Epoch 1 [train]: 100%|██████████| 12/12 [03:07<00:00, 15.60s/it, loss=2.09]\n",
      "Epoch 1 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss=2.0866 val_loss=1.8329\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [train]: 100%|██████████| 12/12 [01:57<00:00,  9.82s/it, loss=1.47]\n",
      "Epoch 2 [val]: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train_loss=1.4689 val_loss=1.3782\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [train]: 100%|██████████| 12/12 [01:36<00:00,  8.03s/it, loss=1.22]\n",
      "Epoch 3 [train]: 100%|██████████| 12/12 [01:36<00:00,  8.03s/it, loss=1.22]\n",
      "Epoch 3 [val]: 100%|██████████| 2/2 [00:00<00:00,  3.05it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train_loss=1.2226 val_loss=1.2749\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [train]: 100%|██████████| 12/12 [01:33<00:00,  7.80s/it, loss=1.16]\n",
      "Epoch 4 [train]: 100%|██████████| 12/12 [01:33<00:00,  7.80s/it, loss=1.16]\n",
      "Epoch 4 [val]: 100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train_loss=1.1626 val_loss=1.1869\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [train]: 100%|██████████| 12/12 [01:35<00:00,  7.95s/it, loss=1.04]\n",
      "Epoch 5 [train]: 100%|██████████| 12/12 [01:35<00:00,  7.95s/it, loss=1.04]\n",
      "Epoch 5 [val]: 100%|██████████| 2/2 [00:00<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train_loss=1.0388 val_loss=1.1622\n",
      "Saved new best to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n",
      "Training complete. Loss history: {'train': [2.086603840192159, 1.4688979784647624, 1.2225753019253414, 1.1626150955756505, 1.0388243645429611], 'val': [1.8328602313995361, 1.378196895122528, 1.2748523354530334, 1.1868975758552551, 1.1622234582901]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5  # increased for small experiment\n",
    "ACCUM_STEPS = 1\n",
    "BEST_VAL = float('inf')\n",
    "best_path = RUN_DIR / 'best.pt'\n",
    "last_path = RUN_DIR / 'last.pt'\n",
    "train_history = []\n",
    "val_history = []\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch} [train]')\n",
    "    total_loss = 0.0\n",
    "    for step, batch in enumerate(pbar, 1):\n",
    "        for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "            batch[k] = batch[k].to(device)\n",
    "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
    "            logits = model(batch)\n",
    "            B, L, V = logits.shape\n",
    "            loss = criterion(logits.view(B*L, V), batch['tgt'].view(B*L)) / ACCUM_STEPS\n",
    "        scaler.scale(loss).backward()\n",
    "        if step % ACCUM_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        total_loss += loss.item() * ACCUM_STEPS\n",
    "        pbar.set_postfix(loss=total_loss/step)\n",
    "    train_epoch_loss = total_loss / max(1, step)\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f'Epoch {epoch} [val]'):\n",
    "            for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "                batch[k] = batch[k].to(device)\n",
    "            logits = model(batch)\n",
    "            B, L, V = logits.shape\n",
    "            loss = criterion(logits.view(B*L, V), batch['tgt'].view(B*L))\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= max(1, len(val_loader))\n",
    "    train_history.append(train_epoch_loss)\n",
    "    val_history.append(val_loss)\n",
    "    print(f'Epoch {epoch} train_loss={train_epoch_loss:.4f} val_loss={val_loss:.4f}')\n",
    "    torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}, last_path)\n",
    "    if val_loss < BEST_VAL:\n",
    "        BEST_VAL = val_loss\n",
    "        torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}, best_path)\n",
    "        print('Saved new best to', best_path)\n",
    "print('Training complete. Loss history:', {'train': train_history, 'val': val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b073d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss curves for the small experiment\n",
    "if train_history and val_history:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_history, label='train_loss')\n",
    "    plt.plot(val_history, label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Experiment Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f968054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 2/2 [00:00<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 2/2 [00:00<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.0, 'cell_accuracy': 0.6699059561128526}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    exact = 0\n",
    "    total = 0\n",
    "    cell_correct = 0\n",
    "    cell_total = 0\n",
    "    for batch in tqdm(loader, desc='Eval'):\n",
    "        for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "            batch[k] = batch[k].to(device)\n",
    "        logits = model(batch)\n",
    "        preds = logits.argmax(-1)\n",
    "        mask = batch['tgt'] != PAD\n",
    "        equal = (preds == batch['tgt']) & mask\n",
    "        cell_correct += equal.sum().item()\n",
    "        cell_total += mask.sum().item()\n",
    "        seq_equal = (equal.sum(dim=1) == mask.sum(dim=1))\n",
    "        exact += seq_equal.sum().item()\n",
    "        total += preds.size(0)\n",
    "    return {\n",
    "        'exact_match': exact / max(1, total),\n",
    "        'cell_accuracy': cell_correct / max(1, cell_total)\n",
    "    }\n",
    "metrics = evaluate(model, val_loader)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9695b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 3 validation examples:\n",
      "Task 15663ba9 subset train index 2\n",
      "Input : [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Target: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 1, 1, 1, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 2, 1, 4, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 4, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 2, 1, 4, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 1, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 1, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 2, 0, 0, 2, 4, 0], [0, 0, 0, 4, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 0], [0, 0, 0, 4, 1, 1, 1, 1, 1, 1, 4, 0, 4, 1, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Pred  : [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "------------------------------------------------------------\n",
      "Task 15663ba9 subset train index 2\n",
      "Input : [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Target: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 1, 1, 1, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 2, 1, 4, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 4, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 2, 1, 4, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 1, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 1, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 2, 0, 0, 2, 4, 0], [0, 0, 0, 4, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 0], [0, 0, 0, 4, 1, 1, 1, 1, 1, 1, 4, 0, 4, 1, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Pred  : [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "------------------------------------------------------------\n",
      "Task 17b80ad2 subset train index 3\n",
      "Input : [[0, 4, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7], [7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9], [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 4, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 6], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 2, 0, 0, 0, 0, 7, 0, 0, 0, 6, 0, 0], [0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0]]\n",
      "Target: [[0, 4, 0, 0, 8, 9, 0, 0, 0, 7, 0, 0, 0, 0, 9, 0, 0], [0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 9, 4, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0], [0, 0, 3, 0, 0, 2, 0, 0, 0, 4, 4, 0, 0, 0, 9, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 7], [7, 0, 0, 0, 0, 2, 0, 9, 0, 4, 0, 0, 0, 0, 6, 0, 9], [0, 0, 0, 3, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 0], [0, 2, 0, 0, 0, 2, 0, 0, 0, 4, 3, 0, 0, 0, 6, 4, 0], [6, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 4, 0, 0, 0, 6, 0, 6], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 2, 0, 0, 6, 0, 0], [0, 8, 0, 0, 0, 2, 0, 0, 0, 4, 7, 0, 0, 0, 6, 0, 0], [0, 0, 6, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0]]\n",
      "Pred  : [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "------------------------------------------------------------\n",
      "Task 17b80ad2 subset train index 3\n",
      "Input : [[0, 4, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7], [7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9], [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 4, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 6], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 2, 0, 0, 0, 0, 7, 0, 0, 0, 6, 0, 0], [0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0]]\n",
      "Target: [[0, 4, 0, 0, 8, 9, 0, 0, 0, 7, 0, 0, 0, 0, 9, 0, 0], [0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 9, 4, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0], [0, 0, 3, 0, 0, 2, 0, 0, 0, 4, 4, 0, 0, 0, 9, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 7], [7, 0, 0, 0, 0, 2, 0, 9, 0, 4, 0, 0, 0, 0, 6, 0, 9], [0, 0, 0, 3, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 0], [0, 2, 0, 0, 0, 2, 0, 0, 0, 4, 3, 0, 0, 0, 6, 4, 0], [6, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 4, 0, 0, 0, 6, 0, 6], [0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 2, 0, 0, 6, 0, 0], [0, 8, 0, 0, 0, 2, 0, 0, 0, 4, 7, 0, 0, 0, 6, 0, 0], [0, 0, 6, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0]]\n",
      "Pred  : [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "------------------------------------------------------------\n",
      "Task 178fcbfb subset train index 0\n",
      "Input : [[0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Target: [[0, 0, 0, 0, 0, 2, 0, 0], [3, 3, 3, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0], [3, 3, 3, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 2, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0]]\n",
      "Pred  : [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "------------------------------------------------------------\n",
      "Task 178fcbfb subset train index 0\n",
      "Input : [[0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Target: [[0, 0, 0, 0, 0, 2, 0, 0], [3, 3, 3, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0], [3, 3, 3, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 2, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0]]\n",
      "Pred  : [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# === Qualitative Predictions (Validation Samples) ===\n",
    "from random import sample as _sample\n",
    "model.eval()\n",
    "num_show = min(3, len(val_samples))\n",
    "show_examples = _sample(val_samples, num_show) if num_show > 0 else []\n",
    "print(f'Showing {len(show_examples)} validation examples:')\n",
    "for ex in show_examples:\n",
    "    grid_in = ex.input\n",
    "    target = ex.output\n",
    "    h_out, w_out = len(target), len(target[0]) if target else (0,0)\n",
    "    enc_tokens = torch.tensor(encode_grid(grid_in), dtype=torch.long).unsqueeze(0).to(device)\n",
    "    h_in, w_in = len(grid_in), len(grid_in[0]) if grid_in else (0,0)\n",
    "    row_idx = torch.tensor([r for r in range(h_in) for _ in range(w_in)], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    col_idx = torch.tensor(list(range(w_in))*h_in, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    pad_mask = torch.zeros_like(enc_tokens, dtype=torch.bool)\n",
    "    max_len = h_out * w_out + 2\n",
    "    gen_seq = model.generate(enc_tokens, row_idx, col_idx, pad_mask, max_len=max_len)[0].cpu().tolist()\n",
    "    pred_grid = decode_grid(gen_seq, h_out, w_out)\n",
    "    print(f'Task {ex.task_id} subset {ex.subset} index {ex.index}')\n",
    "    print('Input :', grid_in)\n",
    "    print('Target:', target)\n",
    "    print('Pred  :', pred_grid)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6189452",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def solve_batch(model, batch, max_len=256):\n",
    "    for k in ['enc','enc_pad_mask','row_idx','col_idx']:\n",
    "        batch[k] = batch[k].to(device)\n",
    "    gen = model.generate(batch['enc'], batch['row_idx'], batch['col_idx'], batch['enc_pad_mask'], max_len=max_len)\n",
    "    preds = gen.cpu().numpy().tolist()\n",
    "    outputs = []\n",
    "    for i, (h_in, w_in, h_out, w_out) in enumerate(batch['meta']):\n",
    "        outputs.append(decode_grid(preds[i], h_out, w_out))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c31b0179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'model': 'ArcTransformer', 'vocab_size': VOCAB_SIZE,\n",
    "    'd_model': 256, 'nhead': 8, 'num_layers': 4, 'dim_ff': 512,\n",
    "    'batch_size': BATCH_SIZE, 'epochs': EPOCHS, 'seed': SEED,\n",
    "}\n",
    "metrics = evaluate(model, val_loader)\n",
    "with (RUN_DIR / 'metrics.json').open('w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "torch.save({'model': model.state_dict(), 'config': config}, RUN_DIR / 'model.pt')\n",
    "with (RUN_DIR / 'config.json').open('w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print('Saved to', RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89c11329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode/Decode test passed\n",
      "Forward pass shape test passed\n",
      "Forward pass shape test passed\n"
     ]
    }
   ],
   "source": [
    "_grid = [[1,2,3],[4,5,6]]\n",
    "assert decode_grid(encode_grid(_grid), 2, 3) == _grid\n",
    "print('Encode/Decode test passed')\n",
    "\n",
    "# Paired augmentation sanity check on first few raw samples (no loader augment to avoid double aug)\n",
    "for i in range(min(3, len(train_samples))):\n",
    "    s = train_samples[i]\n",
    "    aug_in, aug_out = apply_shared_aug(s.input, s.output)\n",
    "    if aug_in and aug_out:\n",
    "        print(f'[AUG SANITY] idx {i} in_shape={len(aug_in)}x{len(aug_in[0])} out_shape={len(aug_out)}x{len(aug_out[0])}')\n",
    "        print('  in_row0:', aug_in[0][:10])\n",
    "        print('  out_row0:', aug_out[0][:10])\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "    batch[k] = batch[k].to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(batch)\n",
    "assert logits.shape[:2] == batch['tgt'].shape\n",
    "print('Forward pass shape test passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d32aeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def sweep(grid):\n",
    "    results = []\n",
    "    for (lr, layers, heads, dropout) in product(grid['lr'], grid['layers'], grid['heads'], grid['dropout']):\n",
    "        m = ArcTransformer(num_layers=layers, nhead=heads).to(device)\n",
    "        opt = torch.optim.AdamW(m.parameters(), lr=lr)\n",
    "        batch = next(iter(train_loader))\n",
    "        for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "            batch[k] = batch[k].to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = m(batch)\n",
    "            B, L, V = logits.shape\n",
    "            loss = criterion(logits.view(B*L, V), batch['tgt'].view(B*L)).item()\n",
    "        results.append({'lr': lr, 'layers': layers, 'heads': heads, 'dropout': dropout, 'loss': loss})\n",
    "    return sorted(results, key=lambda x: x['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "952e2d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchScript export skipped: Tracer cannot infer type of ({'enc': tensor([[ 8,  8,  8,  ..., 10, 10, 10],\n",
      "        [ 8,  8,  8,  ...,  8,  8,  8],\n",
      "        [ 0,  0,  0,  ..., 10, 10, 10],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  ..., 10, 10, 10],\n",
      "        [ 0,  0,  0,  ..., 10, 10, 10],\n",
      "        [ 8,  0,  0,  ..., 10, 10, 10]]), 'dec_in': tensor([[11,  9,  9,  ..., 10, 10, 10],\n",
      "        [11,  0,  0,  ..., 10, 10, 10],\n",
      "        [11,  0,  0,  ..., 10, 10, 10],\n",
      "        ...,\n",
      "        [11,  0,  0,  ..., 10, 10, 10],\n",
      "        [11,  0,  0,  ..., 10, 10, 10],\n",
      "        [11,  8,  0,  ..., 10, 10, 10]]), 'tgt': tensor([[ 9,  9,  9,  ..., 10, 10, 10],\n",
      "        [ 0,  0,  0,  ..., 10, 10, 10],\n",
      "        [ 0,  0,  0,  ..., 10, 10, 10],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  ..., 10, 10, 10],\n",
      "        [ 0,  0,  3,  ..., 10, 10, 10],\n",
      "        [ 8,  0,  0,  ..., 10, 10, 10]]), 'enc_pad_mask': tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]), 'dec_pad_mask': tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]), 'row_idx': tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ..., 21, 21, 21],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0]]), 'col_idx': tensor([[ 0,  1,  2,  ...,  0,  0,  0],\n",
      "        [ 0,  1,  2,  ..., 26, 27, 28],\n",
      "        [ 0,  1,  2,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 0,  1,  2,  ...,  0,  0,  0],\n",
      "        [ 0,  1,  2,  ...,  0,  0,  0],\n",
      "        [ 0,  1,  2,  ...,  0,  0,  0]]), 'meta': [(19, 19, 5, 17), (22, 29, 6, 27), (12, 15, 12, 15), (13, 13, 13, 13), (14, 16, 14, 16), (3, 3, 9, 9), (3, 3, 9, 9), (3, 3, 9, 9), (3, 3, 9, 9), (16, 16, 16, 16), (16, 16, 16, 16), (10, 8, 10, 8), (9, 9, 9, 9), (10, 11, 10, 11), (12, 12, 12, 12), (13, 13, 13, 13)]},)\n",
      ":Dictionary inputs to traced functions must have consistent type. Found Tensor and List[Tuple[int, int, int, int]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    example = next(iter(val_loader))\n",
    "    for k in ['enc','dec_in','tgt','enc_pad_mask','dec_pad_mask','row_idx','col_idx']:\n",
    "        example[k] = example[k].to(device)\n",
    "    ts_path = RUN_DIR / 'model_ts.pt'\n",
    "    scripted = torch.jit.trace(model, (example))\n",
    "    scripted.save(str(ts_path))\n",
    "    print('Saved TorchScript to', ts_path)\n",
    "except Exception as e:\n",
    "    print('TorchScript export skipped:', e)\n",
    "try:\n",
    "    import onnx\n",
    "    onnx_path = RUN_DIR / 'model.onnx'\n",
    "    print('ONNX export not implemented in this baseline')\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "049f64a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval(gen): 100%|██████████| 2/2 [00:53<00:00, 26.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval(gen): 100%|██████████| 2/2 [00:53<00:00, 26.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match_seq': 0.0, 'cell_accuracy_seq': 0.503448275862069}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_generate(model, loader, max_len_factor=1.2):\n",
    "    model.eval()\n",
    "    exact = 0\n",
    "    total = 0\n",
    "    cell_correct = 0\n",
    "    cell_total = 0\n",
    "    for batch in tqdm(loader, desc='Eval(gen)'):\n",
    "        enc = batch['enc'].to(device)\n",
    "        row_idx = batch['row_idx'].to(device)\n",
    "        col_idx = batch['col_idx'].to(device)\n",
    "        enc_pad_mask = batch['enc_pad_mask'].to(device)\n",
    "        gen_max = [max(1, h_out*w_out) + 1 for (_, _, h_out, w_out) in batch['meta']]\n",
    "        max_len = int(max(gen_max) * max_len_factor)\n",
    "        gen = model.generate(enc, row_idx, col_idx, enc_pad_mask, max_len=max_len)\n",
    "        preds = gen.cpu().tolist()\n",
    "        tgt = batch['tgt']\n",
    "        pad_mask = (tgt != PAD)\n",
    "        for i in range(tgt.size(0)):\n",
    "            tlen = pad_mask[i].sum().item()\n",
    "            p = preds[i][:tlen]\n",
    "            t = tgt[i, :tlen].tolist()\n",
    "            cell_total += tlen\n",
    "            cell_correct += sum(int(pi == ti) for pi, ti in zip(p, t))\n",
    "            if p == t:\n",
    "                exact += 1\n",
    "            total += 1\n",
    "    return {\n",
    "        'exact_match_seq': exact / max(1, total),\n",
    "        'cell_accuracy_seq': cell_correct / max(1, cell_total)\n",
    "    }\n",
    "gen_metrics = evaluate_generate(model, val_loader)\n",
    "print(gen_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f1ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d236390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== ArcSeqDataset ==\n",
      "Error getting ArcSeqDataset source: source code not available\n",
      "\n",
      "== collate_fn or collate ==\n",
      "\n",
      "-- collate_batch --\n",
      "\n",
      "def collate_batch(batch):\n",
      "    B = len(batch)\n",
      "    enc_lens = [len(b['enc']) for b in batch]\n",
      "    dec_lens = [len(b['dec_in']) for b in batch]\n",
      "    max_enc = max(enc_lens) if enc_lens else 0\n",
      "    max_dec = max(dec_lens) if dec_lens else 0\n",
      "    enc = torch.full((B, max_enc), PAD, dtype=torch.long)\n",
      "    dec_in = torch.full((B, max_dec), PAD, dtype=torch.long)\n",
      "    tgt = torch.full((B, max_dec), PAD, dtype=torch.long)\n",
      "    enc_pad_mask = torch.ones((B, max_enc), dtype=torch.bool)\n",
      "    dec_pad_mask = torch.ones((B, max_dec), dtype=torch.bool)\n",
      "    row_idx = torch.zeros((B, max_enc), dtype=torch.long)\n",
      "    col_idx = torch.zeros((B, max_enc), dtype=torch.long)\n",
      "    meta = []\n",
      "    for i, b in enumerate(batch):\n",
      "        L_e = len(b['enc']); L_d = len(b['dec_in'])\n",
      "        enc[i, :L_e] = b['enc']\n",
      "        dec_in[i, :L_d] = b['dec_in']\n",
      "        tgt[i, :len(b['tgt'])] = b['tgt']\n",
      "        enc_pad_mask[i, :L_e] = False\n",
      "        dec_pad_mask[i, :L_d] = False\n",
      "        r, c = make_row_col_indices(b['h_in'], b['w_in'])\n",
      "        if L_e > 0 and len(r) == L_e:\n",
      "            row_idx[i, :L_e] = torch.tensor(r, dtype=torch.long)\n",
      "            col_idx[i, :L_e] = torch.tensor(c, dtype=torch.long)\n",
      "        meta.append((b['h_in'], b['w_in'], b['h_out'], b['w_out']))\n",
      "    return {\n",
      "        'enc': enc, 'dec_in': dec_in, 'tgt': tgt,\n",
      "        'enc_pad_mask': enc_pad_mask, 'dec_pad_mask': dec_pad_mask,\n",
      "        'row_idx': row_idx, 'col_idx': col_idx, 'meta': meta\n",
      "    }\n",
      "\n",
      "\n",
      "== tokenization helpers (encode/decode) ==\n",
      "\n",
      "-- encode_grid --\n",
      "\n",
      "def encode_grid(grid: List[List[int]] | List[int] | int) -> List[int]:\n",
      "    arr = normalize_grid(grid)\n",
      "    return arr.reshape(-1).tolist()\n",
      "\n",
      "\n",
      "-- decode_grid --\n",
      "\n",
      "def decode_grid(tokens: List[int], h: int, w: int) -> List[List[int]]:\n",
      "    seq = tokens[: h*w]\n",
      "    return [seq[i*w:(i+1)*w] for i in range(h)]\n",
      "\n",
      "\n",
      "== model.generate ==\n",
      "    @torch.no_grad()\n",
      "    def generate(self, enc, row_idx, col_idx, enc_pad_mask, max_len=256):\n",
      "        self.eval()\n",
      "        memory = self.encode(enc, row_idx, col_idx, src_key_padding_mask=enc_pad_mask)\n",
      "        B = enc.size(0)\n",
      "        ys = torch.full((B, 1), BOS, dtype=torch.long, device=enc.device)\n",
      "        for _ in range(max_len):\n",
      "            logits = self.decode(ys, memory,\n",
      "                                 tgt_key_padding_mask=torch.zeros_like(ys, dtype=torch.bool),\n",
      "                                 memory_key_padding_mask=enc_pad_mask)\n",
      "            next_tok = logits[:, -1].argmax(-1, keepdim=True)\n",
      "            ys = torch.cat([ys, next_tok], dim=1)\n",
      "            if (next_tok == EOS).all():\n",
      "                break\n",
      "        return ys[:, 1:]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from textwrap import indent\n",
    "\n",
    "print(\"== ArcSeqDataset ==\")\n",
    "try:\n",
    "    print(inspect.getsource(ArcSeqDataset))\n",
    "except Exception as e:\n",
    "    print(\"Error getting ArcSeqDataset source:\", e)\n",
    "\n",
    "print(\"\\n== collate_fn or collate ==\")\n",
    "for name in list(globals().keys()):\n",
    "    if name.lower().startswith(\"collate\"):\n",
    "        obj = globals()[name]\n",
    "        if callable(obj):\n",
    "            print(f\"\\n-- {name} --\\n\")\n",
    "            try:\n",
    "                print(inspect.getsource(obj))\n",
    "            except Exception as e:\n",
    "                print(\"(no source)\", e)\n",
    "\n",
    "print(\"\\n== tokenization helpers (encode/decode) ==\")\n",
    "for name in [n for n in globals().keys() if any(n.lower().startswith(p) for p in (\"encode\",\"decode\",\"grid_to\",\"seq_to\"))]:\n",
    "    obj = globals()[name]\n",
    "    if callable(obj):\n",
    "        print(f\"\\n-- {name} --\\n\")\n",
    "        try:\n",
    "            print(inspect.getsource(obj))\n",
    "        except Exception as e:\n",
    "            print(\"(no source)\", e)\n",
    "\n",
    "print(\"\\n== model.generate ==\")\n",
    "try:\n",
    "    print(inspect.getsource(model.generate))\n",
    "except Exception as e:\n",
    "    print(\"Error getting model.generate source:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2926c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample 0:\n",
      "keys: ['enc', 'dec_in', 'tgt', 'h_in', 'w_in', 'h_out', 'w_out']\n",
      "enc: <class 'torch.Tensor'> -> tensor([7, 3, 9, 4])\n",
      "dec_in: <class 'torch.Tensor'> -> tensor([11,  9,  7,  3,  4,  9,  7,  3,  4,  9,  7,  3,  4,  9,  7,  3,  4,  9,\n",
      "         7,  3,  4,  9,  7,  3,  4,  9,  7,  3,  4,  9,  7,  3,  4,  9,  7,  3,\n",
      "         4])\n",
      "tgt: <class 'torch.Tensor'> -> tensor([ 9,  7,  3,  4,  9,  7,  3,  4,  9,  7,  3,  4,  9,  7,  3,  4,  9,  7,\n",
      "         3,  4,  9,  7,  3,  4,  9,  7,  3,  4,  9,  7,  3,  4,  9,  7,  3,  4,\n",
      "        12])\n",
      "h_in 2\n",
      "w_in 2\n",
      "h_out 6\n",
      "w_out 6\n",
      "\n",
      "Val sample 0:\n",
      "keys: ['enc', 'dec_in', 'tgt', 'h_in', 'w_in', 'h_out', 'w_out']\n",
      "enc: <class 'torch.Tensor'> -> tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 1, 1, 1, 1,\n",
      "        1, 8, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 8, 5, 1, 8, 2, 8, 1, 8, 1, 6, 6,\n",
      "        6, 1, 8, 1, 7, 7, 7, 1, 8, 5, 1, 2, 2, 2, 1, 8, 1, 6, 6, 6, 1, 8, 1, 7,\n",
      "        7, 7, 1, 8, 5, 1, 8, 2, 8, 1, 8, 1, 6, 6, 6, 1, 8, 1, 7, 7, 7, 1, 8, 5,\n",
      "        1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1,\n",
      "        1, 8, 1, 1, 1, 1, 1, 8, 9, 1, 3, 3, 3, 1, 8, 1, 2, 8, 8, 1, 8, 1, 2, 2,\n",
      "        2, 1, 8, 9, 1, 3, 3, 3, 1, 8, 1, 2, 2, 8, 1, 8, 1, 8, 2, 8, 1, 8, 9, 1,\n",
      "        3, 3, 3, 1, 8, 1, 8, 2, 2, 1, 8, 1, 8, 8, 8, 1, 8, 9, 1, 1, 1, 1, 1, 8,\n",
      "        1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 0, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1,\n",
      "        1, 8, 0, 1, 8, 2, 8, 1, 8, 1, 2, 8, 8, 1, 8, 1, 2, 2, 2, 1, 8, 0, 1, 2,\n",
      "        2, 2, 1, 8, 1, 2, 2, 8, 1, 8, 1, 8, 2, 8, 1, 8, 0, 1, 8, 2, 8, 1, 8, 1,\n",
      "        8, 2, 2, 1, 8, 1, 8, 8, 8, 1, 8, 0, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 8,\n",
      "        1, 1, 1, 1, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8])\n",
      "dec_in: <class 'torch.Tensor'> -> tensor([11,  9,  9,  9,  9,  9,  8,  5,  5,  5,  5,  5,  8,  5,  5,  5,  5,  5,\n",
      "         9,  8,  3,  8,  9,  8,  5,  6,  8,  8,  5,  8,  5,  7,  7,  7,  5,  9,\n",
      "         3,  3,  3,  9,  8,  5,  6,  6,  8,  5,  8,  5,  8,  7,  8,  5,  9,  8,\n",
      "         3,  8,  9,  8,  5,  8,  6,  6,  5,  8,  5,  8,  8,  8,  5,  9,  9,  9,\n",
      "         9,  9,  8,  5,  5,  5,  5,  5,  8,  5,  5,  5,  5,  5])\n",
      "tgt: <class 'torch.Tensor'> -> tensor([ 9,  9,  9,  9,  9,  8,  5,  5,  5,  5,  5,  8,  5,  5,  5,  5,  5,  9,\n",
      "         8,  3,  8,  9,  8,  5,  6,  8,  8,  5,  8,  5,  7,  7,  7,  5,  9,  3,\n",
      "         3,  3,  9,  8,  5,  6,  6,  8,  5,  8,  5,  8,  7,  8,  5,  9,  8,  3,\n",
      "         8,  9,  8,  5,  8,  6,  6,  5,  8,  5,  8,  8,  8,  5,  9,  9,  9,  9,\n",
      "         9,  8,  5,  5,  5,  5,  5,  8,  5,  5,  5,  5,  5, 12])\n",
      "h_in 19\n",
      "w_in 19\n",
      "h_out 5\n",
      "w_out 17\n",
      "\n",
      "train_loader.collate_fn: <function collate_batch at 0x000002CB50B33BA0>\n"
     ]
    }
   ],
   "source": [
    "def peek_sample(ds, idx=0):\n",
    "    s = ds[idx]\n",
    "    print(\"keys:\", list(s.keys()))\n",
    "    for k in (\"enc\",\"dec_in\",\"tgt\"):\n",
    "        v = s.get(k)\n",
    "        if isinstance(v, list):\n",
    "            print(f\"{k}: len={len(v)} head={v[:10]}\")\n",
    "        else:\n",
    "            print(f\"{k}: {type(v)} -> {v}\")\n",
    "    for k in (\"h_in\",\"w_in\",\"h_out\",\"w_out\"):\n",
    "        print(k, s.get(k))\n",
    "\n",
    "print(\"Train sample 0:\")\n",
    "peek_sample(train_ds, 0)\n",
    "\n",
    "print(\"\\nVal sample 0:\")\n",
    "peek_sample(val_ds, 0)\n",
    "\n",
    "print(\"\\ntrain_loader.collate_fn:\", getattr(train_loader, 'collate_fn', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f5c2b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len summaries:\n",
      "{'avg_dec_in': 134.4, 'avg_tgt': 134.4, 'avg_area': 133.4, 'eos_present_cnt': 20}\n",
      "First 3: [{'i': 0, 'dec_in': 37, 'tgt': 37, 'area': 36, 'has_eos': tensor(True)}, {'i': 1, 'dec_in': 37, 'tgt': 37, 'area': 36, 'has_eos': tensor(True)}, {'i': 2, 'dec_in': 82, 'tgt': 82, 'area': 81, 'has_eos': tensor(True)}]\n",
      "\n",
      "Val len summaries:\n",
      "{'avg_dec_in': 159.5, 'avg_tgt': 159.5, 'avg_area': 158.5, 'eos_present_cnt': 20}\n",
      "First 3: [{'i': 0, 'dec_in': 86, 'tgt': 86, 'area': 85, 'has_eos': tensor(True)}, {'i': 1, 'dec_in': 163, 'tgt': 163, 'area': 162, 'has_eos': tensor(True)}, {'i': 2, 'dec_in': 181, 'tgt': 181, 'area': 180, 'has_eos': tensor(True)}]\n"
     ]
    }
   ],
   "source": [
    "def has_eos(sample):\n",
    "    return len(sample['tgt']) > 0 and sample['tgt'][-1] == EOS\n",
    "\n",
    "# Inspect first 20 samples from train/val\n",
    "train_checks = []\n",
    "for i in range(min(20, len(train_ds))):\n",
    "    s = train_ds[i]\n",
    "    area = int(s['h_out']) * int(s['w_out'])\n",
    "    train_checks.append({\n",
    "        'i': i,\n",
    "        'dec_in': len(s['dec_in']),\n",
    "        'tgt': len(s['tgt']),\n",
    "        'area': area,\n",
    "        'has_eos': has_eos(s)\n",
    "    })\n",
    "\n",
    "val_checks = []\n",
    "for i in range(min(20, len(val_ds))):\n",
    "    s = val_ds[i]\n",
    "    area = int(s['h_out']) * int(s['w_out'])\n",
    "    val_checks.append({\n",
    "        'i': i,\n",
    "        'dec_in': len(s['dec_in']),\n",
    "        'tgt': len(s['tgt']),\n",
    "        'area': area,\n",
    "        'has_eos': has_eos(s)\n",
    "    })\n",
    "\n",
    "print('Train len summaries:')\n",
    "print({\n",
    "    'avg_dec_in': sum(x['dec_in'] for x in train_checks)/len(train_checks),\n",
    "    'avg_tgt': sum(x['tgt'] for x in train_checks)/len(train_checks),\n",
    "    'avg_area': sum(x['area'] for x in train_checks)/len(train_checks),\n",
    "    'eos_present_cnt': sum(1 for x in train_checks if x['has_eos'])\n",
    "})\n",
    "print('First 3:', train_checks[:3])\n",
    "\n",
    "print('\\nVal len summaries:')\n",
    "print({\n",
    "    'avg_dec_in': sum(x['dec_in'] for x in val_checks)/len(val_checks),\n",
    "    'avg_tgt': sum(x['tgt'] for x in val_checks)/len(val_checks),\n",
    "    'avg_area': sum(x['area'] for x in val_checks)/len(val_checks),\n",
    "    'eos_present_cnt': sum(1 for x in val_checks if x['has_eos'])\n",
    "})\n",
    "print('First 3:', val_checks[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "576807a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best checkpoint: c:\\Users\\aibel\\OneDrive\\Documents\\Code\\arc-agi\\models\\run_20250824-113414\\best.pt\n",
      "Generate eval (val): {'exact_match': 0.0, 'cell_accuracy': 0.5066246056782334, 'n_examples': 20}\n",
      "Generate eval (val): {'exact_match': 0.0, 'cell_accuracy': 0.5066246056782334, 'n_examples': 20}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_best(model, path):\n",
    "    if os.path.exists(path):\n",
    "        sd = torch.load(path, map_location=device)\n",
    "        if isinstance(sd, dict) and 'model' in sd:\n",
    "            model.load_state_dict(sd['model'])\n",
    "        else:\n",
    "            model.load_state_dict(sd)\n",
    "        print(f\"Loaded best checkpoint: {path}\")\n",
    "    else:\n",
    "        print(f\"Best checkpoint not found: {path}\")\n",
    "load_best(model, str(best_path))\n",
    "\n",
    "# NOTE: Model may have been trained before paired augmentation fix; consider retraining for cleaner learning signal.\n",
    "@torch.no_grad()\n",
    "def evaluate_generate(model, loader, max_gen_len=None, limit=None):\n",
    "    model.eval()\n",
    "    total_cells = 0\n",
    "    correct_cells = 0\n",
    "    exact_matches = 0\n",
    "    total_examples = 0\n",
    "    for bi, batch in enumerate(loader):\n",
    "        enc = batch['enc'].to(device)\n",
    "        enc_pad = batch['enc_pad_mask'].to(device)\n",
    "        row_idx = batch['row_idx'].to(device)\n",
    "        col_idx = batch['col_idx'].to(device)\n",
    "        tgt = batch['tgt'].to(device)\n",
    "        B = enc.size(0)\n",
    "        metas = batch['meta']\n",
    "        areas = [int(h_out) * int(w_out) for (_, _, h_out, w_out) in metas]\n",
    "        max_area = max(areas) if areas else 0\n",
    "        max_len = max_gen_len or (max_area + 2)\n",
    "        ys = model.generate(enc, row_idx, col_idx, enc_pad, max_len=max_len)\n",
    "        for i in range(B):\n",
    "            area = areas[i]\n",
    "            tgt_seq = tgt[i, :area]\n",
    "            pred = ys[i]\n",
    "            eos_pos = (pred == EOS).nonzero(as_tuple=False)\n",
    "            if len(eos_pos) > 0:\n",
    "                pred = pred[: int(eos_pos[0].item())]\n",
    "            pred_area = pred[:area]\n",
    "            if pred_area.numel() < area:\n",
    "                pad = torch.full((area - pred_area.numel(),), PAD, dtype=pred_area.dtype, device=pred_area.device)\n",
    "                pred_area = torch.cat([pred_area, pad], dim=0)\n",
    "            else:\n",
    "                pred_area = pred_area[:area]\n",
    "            correct = (pred_area == tgt_seq).sum().item()\n",
    "            correct_cells += correct\n",
    "            total_cells += area\n",
    "            if correct == area and pred.numel() >= area:\n",
    "                exact_matches += 1\n",
    "            total_examples += 1\n",
    "        if limit and total_examples >= limit:\n",
    "            break\n",
    "    return {\n",
    "        'exact_match': exact_matches / max(1, total_examples),\n",
    "        'cell_accuracy': correct_cells / max(1, total_cells),\n",
    "        'n_examples': total_examples,\n",
    "    }\n",
    "metrics_gen = evaluate_generate(model, val_loader, max_gen_len=MAX_H*MAX_W+2)\n",
    "print(\"Generate eval (val):\", metrics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1b0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbd721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random, numpy as np, matplotlib.pyplot as plt, torch\n",
    "\n",
    "if 'val_samples' not in globals():\n",
    "    print('val_samples not defined; run earlier cells first.')\n",
    "else:\n",
    "    random.seed(1234)\n",
    "    n_show = min(5, len(val_samples))\n",
    "    picked = random.sample(val_samples, n_show) if n_show else []\n",
    "    print(f\"Showing {len(picked)} validation samples\")\n",
    "\n",
    "    def _predict_grid(grid_in, target_out):\n",
    "        h_out = len(target_out)\n",
    "        w_out = len(target_out[0]) if h_out else 0\n",
    "        enc_tokens = torch.tensor(encode_grid(grid_in), dtype=torch.long).unsqueeze(0).to(device)\n",
    "        h_in = len(grid_in); w_in = len(grid_in[0]) if h_in else 0\n",
    "        row_idx = torch.tensor([r for r in range(h_in) for _ in range(w_in)], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        col_idx = torch.tensor(list(range(w_in))*h_in, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        pad_mask = torch.zeros_like(enc_tokens, dtype=torch.bool)\n",
    "        max_len = h_out * w_out + 2\n",
    "        with torch.no_grad():\n",
    "            gen_seq = model.generate(enc_tokens, row_idx, col_idx, pad_mask, max_len=max_len)[0].cpu().tolist()\n",
    "        pred_grid = decode_grid(gen_seq, h_out, w_out)\n",
    "        return pred_grid\n",
    "\n",
    "    def _grid_accuracy(pred, tgt):\n",
    "        if not tgt: return 0.0, False\n",
    "        flat_t = [c for row in tgt for c in row]\n",
    "        flat_p = [c for row in pred for c in row][:len(flat_t)]\n",
    "        correct = sum(int(a==b) for a,b in zip(flat_p, flat_t))\n",
    "        return correct / max(1, len(flat_t)), (correct == len(flat_t))\n",
    "\n",
    "    def _show_color_grid(ax, grid, title):\n",
    "        arr = np.array(grid if grid else [[]], dtype=int)\n",
    "        cmap = plt.get_cmap('tab10', 10)\n",
    "        if arr.size == 0:\n",
    "            ax.text(0.5,0.5,'(empty)', ha='center', va='center')\n",
    "        else:\n",
    "            ax.imshow(arr, cmap=cmap, vmin=0, vmax=9)\n",
    "        ax.set_title(title, fontsize=9)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "    if n_show == 0:\n",
    "        print('No validation samples available.')\n",
    "    else:\n",
    "        rows, cols = n_show, 3\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\n",
    "        if rows == 1:\n",
    "            axes = np.array([axes])\n",
    "        cell_accs, exact_flags = [], []\n",
    "        for r, ex in enumerate(picked):\n",
    "            inp = ex.input\n",
    "            tgt = ex.output\n",
    "            pred = _predict_grid(inp, tgt)\n",
    "            acc, exact = _grid_accuracy(pred, tgt)\n",
    "            cell_accs.append(acc); exact_flags.append(exact)\n",
    "            _show_color_grid(axes[r,0], inp, f\"In {ex.task_id[:6]} {ex.subset}[{ex.index}]\")\n",
    "            _show_color_grid(axes[r,1], tgt, 'Target')\n",
    "            _show_color_grid(axes[r,2], pred, f\"Pred acc={acc*100:.1f}% {'✓' if exact else ''}\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "        overall_cell_acc = sum(cell_accs)/len(cell_accs) if cell_accs else 0.0\n",
    "        overall_exact = sum(exact_flags)/len(exact_flags) if exact_flags else 0.0\n",
    "        print({'samples': len(picked), 'avg_cell_accuracy': overall_cell_acc, 'exact_match_rate': overall_exact})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
